 ì´ ì½”ë“œëŠ” íŠ¹ì • ì›¹ì‚¬ì´íŠ¸ì˜ ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , íŒŒì¼ ì´ë¦„ì„ "ì¹´í…Œê³ ë¦¬.ì œëª©.jpg" í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤.

1. ë””ë ‰í† ë¦¬ ì¤€ë¹„
python
output_dir = "downloaded_images"
if not os.path.exists(output_dir):
    os.makedirs(output_dir

ëª©ì : ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
output_dirëŠ” ì €ì¥í•  ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œì…ë‹ˆë‹¤.
os.makedirs(output_dir)ëŠ” ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šì„ ê²½ìš° ìƒì„±í•©ë‹ˆë‹¤.

2. HTTP ìš”ì²­ í—¤ë” ì„¤ì •
python
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36"
}
ëª©ì : ì„œë²„ì™€ì˜ ìš”ì²­ì—ì„œ ë¸Œë¼ìš°ì €ì²˜ëŸ¼ ë³´ì´ë„ë¡ í•˜ê¸° ìœ„í•´ ìš”ì²­ í—¤ë”ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
ì›¹ì‚¬ì´íŠ¸ëŠ” ë¸Œë¼ìš°ì €ê°€ ì•„ë‹Œ í”„ë¡œê·¸ë¨(í¬ë¡¤ëŸ¬)ìœ¼ë¡œë¶€í„°ì˜ ìš”ì²­ì„ ì°¨ë‹¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ User-Agentë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.

3. URL í…œí”Œë¦¿ê³¼ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
python
base_url = "https://hornygrail.com/new/{}"
start_page = int(input("Enter the start page number: "))
end_page = int(input("Enter the end page number: "))
base_url: íŠ¹ì • ì›¹ì‚¬ì´íŠ¸ì˜ í˜ì´ì§€ URLì„ êµ¬ì„±í•˜ëŠ” í…œí”Œë¦¿ì…ë‹ˆë‹¤. {}ëŠ” í˜ì´ì§€ ë²ˆí˜¸ê°€ ì‚½ì…ë  ìœ„ì¹˜ì…ë‹ˆë‹¤.
start_page, end_page: ì‚¬ìš©ìê°€ í¬ë¡¤ë§í•  ì‹œì‘ í˜ì´ì§€ì™€ ë í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
ì˜ˆë¥¼ ë“¤ì–´, ì‹œì‘ í˜ì´ì§€ê°€ 1, ë í˜ì´ì§€ê°€ 3ì´ë©´ í˜ì´ì§€ 1, 2, 3ì„ ìˆœíšŒí•©ë‹ˆë‹¤.

4. í˜ì´ì§€ ìˆœíšŒ
python
for page in range(start_page, end_page + 1):
    print(f"Processing page {page}...")
    target_url = base_url.format(page)
ëª©ì : ì‹œì‘ í˜ì´ì§€ë¶€í„° ë í˜ì´ì§€ê¹Œì§€ ìˆœíšŒí•˜ë©° ê°ê°ì˜ í˜ì´ì§€ URLì„ ìƒì„±í•©ë‹ˆë‹¤.
base_url.format(page): í…œí”Œë¦¿ì˜ {}ì— í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì‚½ì…í•˜ì—¬ ìš”ì²­í•  URLì„ ìƒì„±í•©ë‹ˆë‹¤.

5. ì›¹ í˜ì´ì§€ HTML ê°€ì ¸ì˜¤ê¸°
python
response = requests.get(target_url, headers=headers)
if response.status_code == 200:
    soup = BeautifulSoup(response.text, "html.parser")
requests.get(target_url, headers=headers): ì§€ì •í•œ URLë¡œ HTTP ìš”ì²­ì„ ë³´ëƒ…ë‹ˆë‹¤.
response.status_code: ì‘ë‹µ ìƒíƒœ ì½”ë“œë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
ìƒíƒœ ì½”ë“œê°€ 200ì´ë©´ ìš”ì²­ ì„±ê³µì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
BeautifulSoup(response.text, "html.parser"): HTMLì„ íŒŒì‹±í•˜ì—¬ DOM êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ HTML ìš”ì†Œì— ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

6. ì´ë¯¸ì§€ ì¹´ë“œ ìš”ì†Œ ì°¾ê¸°
python
cards = soup.find_all("div", class_="card")
print(f"Found {len(cards)} cards on page {page}.")
soup.find_all("div", class_="card"): HTMLì—ì„œ div íƒœê·¸ ì¤‘ í´ë˜ìŠ¤ ì´ë¦„ì´ cardì¸ ëª¨ë“  ìš”ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
ì´ ë¶€ë¶„ì€ ì‚¬ì´íŠ¸ì˜ êµ¬ì¡°ì— ë”°ë¼ ìˆ˜ì •ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

7. ì¹´í…Œê³ ë¦¬ì™€ ì œëª© ì¶”ì¶œ
python
category_tag = card.find("div", class_="card-body__info tag")
title_tag = card.find("div", class_="card-body__line")

category = category_tag.text.strip() if category_tag else "Uncategorized"
title = title_tag.text.strip() if title_tag else "Untitled"
ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ:
card.find("div", class_="card-body__info tag"): ì´ë¯¸ì§€ ì¹´ë“œì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìš”ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
.text.strip(): í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œí•˜ê³  ì–‘ìª½ ê³µë°±ì„ ì œê±°í•©ë‹ˆë‹¤.
else "Uncategorized": ì¹´í…Œê³ ë¦¬ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ì„ ì„¤ì •í•©ë‹ˆë‹¤.
ì œëª© ì¶”ì¶œ: ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì œëª©ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

8. íŒŒì¼ ì´ë¦„ ìƒì„±
python
sanitized_category = "".join(c if c.isalnum() or c in " _-" else "_" for c in category)
sanitized_title = "".join(c if c.isalnum() or c in " _-" else "_" for c in title)
file_name = f"{sanitized_category}.{sanitized_title}.jpg"
ëª©ì : íŒŒì¼ ì´ë¦„ì— í¬í•¨ë  ì¹´í…Œê³ ë¦¬ì™€ ì œëª©ì—ì„œ ë¶ˆë²• ë¬¸ìë¥¼ ì œê±°í•©ë‹ˆë‹¤.
isalnum(): ë¬¸ìì™€ ìˆ«ìë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
" _-": ê³µë°±, ì–¸ë”ìŠ¤ì½”ì–´(_), í•˜ì´í”ˆ(-)ì€ í—ˆìš©í•©ë‹ˆë‹¤.
file_name: ìµœì¢… íŒŒì¼ ì´ë¦„ì€ ì¹´í…Œê³ ë¦¬.ì œëª©.jpg í˜•ì‹ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.

9. ì´ë¯¸ì§€ URL ì¶”ì¶œ ë° ë‹¤ìš´ë¡œë“œ
python
img_tag = card.find("img")
img_url = img_tag.get("src") if img_tag else None
if not img_url:
    continue

if not img_url.startswith("http"):
    img_url = requests.compat.urljoin(target_url, img_url)
ì´ë¯¸ì§€ URL ì¶”ì¶œ: ì¹´ë“œì—ì„œ <img> íƒœê·¸ë¥¼ ì°¾ê³ , src ì†ì„±ì—ì„œ ì´ë¯¸ì§€ URLì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
ì ˆëŒ€ URL ë³€í™˜: ì´ë¯¸ì§€ URLì´ ìƒëŒ€ ê²½ë¡œì¼ ê²½ìš°, requests.compat.urljoinì„ ì‚¬ìš©í•˜ì—¬ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

10. ì´ë¯¸ì§€ ì €ì¥
python
file_path = os.path.join(output_dir, file_name)
if os.path.exists(file_path):
    print(f"File already exists: {file_path}")
    continue

img_data = requests.get(img_url).content
with open(file_path, "wb") as img_file:
    img_file.write(img_data)
print(f"Downloaded: {file_path}")
ì €ì¥ ê²½ë¡œ: íŒŒì¼ ì´ë¦„ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ë¥¼ ê²°í•©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ìµœì¢… ê²½ë¡œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
ì¤‘ë³µ í™•ì¸: íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•  ê²½ìš° ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.
ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ:
requests.get(img_url).content: ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
with open(file_path, "wb"): ë°”ì´ë„ˆë¦¬ ëª¨ë“œë¡œ íŒŒì¼ì„ ì—´ê³  ë°ì´í„°ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

11. ëŒ€ê¸° ì‹œê°„
python
time.sleep(1)
ëª©ì : í¬ë¡¤ë§ ë°©ì§€ë¥¼ ìœ„í•´ ìš”ì²­ ê°„ì— 1ì´ˆì˜ ëŒ€ê¸° ì‹œê°„ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
í•„ìš”ì— ë”°ë¼ ë” ê¸¸ê²Œ ì„¤ì •í•˜ê±°ë‚˜ ëœë¤í•œ ëŒ€ê¸° ì‹œê°„ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

12. ì™„ë£Œ ë©”ì‹œì§€
python
print("Download complete.")
ëª¨ë“  í˜ì´ì§€ì˜ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´ ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

í”„ë¡œê·¸ë¨ íë¦„ ìš”ì•½
ì‚¬ìš©ìì—ê²Œ ì‹œì‘ í˜ì´ì§€ì™€ ë í˜ì´ì§€ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
ê° í˜ì´ì§€ì˜ URLì— ì ‘ê·¼í•˜ì—¬ HTMLì„ íŒŒì‹±í•©ë‹ˆë‹¤.
ì¹´ë“œ ìš”ì†Œë¥¼ ìˆœíšŒí•˜ë©° ì¹´í…Œê³ ë¦¬, ì œëª©, ì´ë¯¸ì§€ URLì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³ , ì¹´í…Œê³ ë¦¬ì™€ ì œëª©ì„ ì¡°í•©í•œ íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
ëª¨ë“  ì‘ì—…ì´ ëë‚˜ë©´ ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.

ì¥ì 
íŒŒì¼ ì´ë¦„ì— ì¹´í…Œê³ ë¦¬ì™€ ì œëª©ì„ í¬í•¨í•´ ì •ë¦¬ê°€ ì‰½ìŠµë‹ˆë‹¤.
ë¶ˆë²• ë¬¸ìë¥¼ ì œê±°í•´ ì €ì¥ ì‹œ ì˜¤ë¥˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
ì¤‘ë³µ íŒŒì¼ì„ ê±´ë„ˆë›°ê³  ì˜ˆì™¸ ì²˜ë¦¬ê°€ í¬í•¨ë˜ì–´ ì•ˆì •ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ê°œì„  ìš”ì²­ì´ ìˆë‹¤ë©´ ë§ì”€í•´ì£¼ì„¸ìš”! ğŸ˜Š
